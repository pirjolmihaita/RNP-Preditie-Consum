{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45a2f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: prophet in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (0.14.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from prophet) (1.3.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from prophet) (3.10.6)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from prophet) (0.86)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from prophet) (4.67.1)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from prophet) (6.5.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from statsmodels) (1.15.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from statsmodels) (1.0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: rich in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.2.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from xgboost) (2.2.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\pirjo\\anaconda3\\envs\\rnp_proiect\\lib\\site-packages (from xgboost) (1.15.3)\n"
     ]
    }
   ],
   "source": [
    "#instalare dependente\n",
    "!pip install pandas numpy tensorflow prophet statsmodels\n",
    "!pip install xgboost lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a4ef15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- START MODEL TRAINING  ---\n",
      "Incarcare date... GATA!\n",
      "[INFO] Input Features: 6 (inclusiv Cluster pt regimuri)\n",
      "\n",
      "--- 1. PROPHET (Tuned) ---\n",
      "   -> Fit Prophet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:08:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:17:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Predictie Prophet...\n",
      "Gata. Timp: 594.8s\n",
      "\n",
      "--- 2. STACKED LSTM (Robust Loss) ---\n",
      "   -> Antrenare LSTM...\n",
      "Epoch 1/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 35ms/step - loss: 0.2144\n",
      "Epoch 2/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 37ms/step - loss: 0.1800\n",
      "Epoch 3/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 37ms/step - loss: 0.1706\n",
      "Epoch 4/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 38ms/step - loss: 0.1660\n",
      "Epoch 5/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 38ms/step - loss: 0.1614\n",
      "Gata. Timp: 2131.6s\n",
      "\n",
      "--- 3. GRU ---\n",
      "   -> Antrenare GRU...\n",
      "Epoch 1/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m592s\u001b[0m 51ms/step - loss: 0.2058\n",
      "Epoch 2/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 54ms/step - loss: 0.1705\n",
      "Epoch 3/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 48ms/step - loss: 0.1623\n",
      "Epoch 4/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 42ms/step - loss: 0.1585\n",
      "Epoch 5/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 39ms/step - loss: 0.1558\n",
      "Gata. Timp: 2686.0s\n",
      "\n",
      "--- 4. SIMPLE RNN (Vanilla - Tuned) ---\n",
      "   -> Antrenare RNN...\n",
      "Epoch 1/5\n",
      "\u001b[1m5751/5751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - loss: 3.4716\n",
      "Epoch 2/5\n",
      "\u001b[1m5751/5751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 7ms/step - loss: 2.3973\n",
      "Epoch 3/5\n",
      "\u001b[1m5751/5751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - loss: 2.1290\n",
      "Epoch 4/5\n",
      "\u001b[1m5751/5751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - loss: 1.9748\n",
      "Epoch 5/5\n",
      "\u001b[1m5751/5751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - loss: 1.8825\n",
      "Gata. Timp: 206.5s\n",
      "   -> Antrenare DeepAR ...\n",
      "Epoch 1/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 32ms/step - loss: -0.3290\n",
      "Epoch 2/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 38ms/step - loss: -0.6620\n",
      "Epoch 3/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 37ms/step - loss: -0.7508\n",
      "Epoch 4/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 37ms/step - loss: -0.8036\n",
      "Epoch 5/5\n",
      "\u001b[1m11501/11501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 37ms/step - loss: -0.8377\n",
      "   -> Predictie DeepAR...\n",
      "Gata. Timp antrenare: 2093.5 s.\n",
      "\n",
      "--- 6. XGBoost & LightGBM (Machine Learning Clasic) ---\n",
      "   -> Generare LAG-uri si Rolling Stats...\n",
      "\n",
      "   -> Antrenare XGBoost...\n",
      "XGBoost GATA (5.5s) | MAE: 53.04 W | MSE: 50192.98\n",
      "\n",
      "   -> Antrenare LightGBM...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's l1: 55.4509\tvalid_0's l2: 50107.5\n",
      "LightGBM GATA (2.2s) | MAE: 55.45 W | MSE: 50107.46\n",
      "\n",
      "Salvare pachet rezultate...\n",
      "TOTUL GATA! Rezultatele sunt in 'model_results_final.pkl. Poti rula 03_Analysis_Comparison.ipynb'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber, MeanAbsoluteError\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from prophet import Prophet\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "# --- CONFIGURARE GENERALA ---\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"--- START MODEL TRAINING  ---\", flush=True)\n",
    "\n",
    "# 1. INCARCARE DATE PROCESATE\n",
    "print(\"Incarcare date...\", end=\"\", flush=True)\n",
    "try:\n",
    "    with open('processed_data.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(\" GATA!\", flush=True)\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n[EROARE] Nu gasesc fisierul 'processed_data.pkl'. Ruleaza intai pasii de preprocesare.\")\n",
    "    raise\n",
    "\n",
    "# Extragere variabile din pachet\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_test = data['X_test']\n",
    "test_data = data['test_data']\n",
    "scaler = data['scaler'] \n",
    "df_1min = data['df_1min'] \n",
    "train_size = data['train_size']\n",
    "WINDOW_SIZE = data['WINDOW_SIZE']\n",
    "\n",
    "# Verificam dimensiunea input-ului (cate features avem?)\n",
    "\n",
    "n_features = X_train.shape[2]\n",
    "print(f\"[INFO] Input Features: {n_features} (inclusiv Cluster pt regimuri)\", flush=True)\n",
    "\n",
    "# Dictionare rezultate\n",
    "rezultate = {}\n",
    "timpi = {}\n",
    "\n",
    "# ======================================================\n",
    "# MODEL 1: PROPHET (Ajustat cu Sezonalitate & Regresori)\n",
    "# ======================================================\n",
    "print(\"\\n--- 1. PROPHET (Tuned) ---\", flush=True)\n",
    "\n",
    "# Pregatire dataset specific Prophet\n",
    "# Prophet vrea coloane: 'ds' (timp), 'y' (target).\n",
    "df_prophet = df_1min.reset_index()[['dt', 'Aggregate', 'Cluster', 'Hour_Sin', 'Hour_Cos', 'IsWeekend']]\n",
    "df_prophet.columns = ['ds', 'y', 'Cluster', 'Hour_Sin', 'Hour_Cos', 'IsWeekend']\n",
    "\n",
    "df_prophet_train = df_prophet.iloc[:train_size]\n",
    "df_prophet_test = df_prophet.iloc[train_size:]\n",
    "\n",
    "# Configurare CERINTA: daily_seasonality=True, weekly_seasonality=True\n",
    "m_prophet = Prophet(\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    uncertainty_samples=0\n",
    ")\n",
    "\n",
    "# Adaugam informatiile extra (Regimuri + Timp)\n",
    "m_prophet.add_regressor('Cluster')    \n",
    "m_prophet.add_regressor('Hour_Sin')   # Info ciclica\n",
    "m_prophet.add_regressor('IsWeekend')  # Info weekend\n",
    "\n",
    "# Antrenare\n",
    "start = time.time()\n",
    "print(\"   -> Fit Prophet...\", flush=True)\n",
    "m_prophet.fit(df_prophet_train)\n",
    "timpi['Prophet'] = time.time() - start\n",
    "\n",
    "# Predictie\n",
    "print(\"   -> Predictie Prophet...\", flush=True)\n",
    "future = m_prophet.make_future_dataframe(periods=len(df_prophet_test), freq='1min')\n",
    "# Trebuie sa adaugam valorile regressorilor pentru viitor (le luam din test set)\n",
    "future['Cluster'] = pd.concat([df_prophet_train['Cluster'], df_prophet_test['Cluster']]).values\n",
    "future['Hour_Sin'] = pd.concat([df_prophet_train['Hour_Sin'], df_prophet_test['Hour_Sin']]).values\n",
    "future['IsWeekend'] = pd.concat([df_prophet_train['IsWeekend'], df_prophet_test['IsWeekend']]).values\n",
    "\n",
    "forecast = m_prophet.predict(future)\n",
    "pred_prophet = forecast['yhat'].iloc[-len(df_prophet_test):].values\n",
    "rezultate['Prophet'] = pred_prophet\n",
    "print(f\"Gata. Timp: {timpi['Prophet']:.1f}s\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# MODEL 2: STACKED LSTM (Cerinta: 2-4 straturi, Dropout, Huber)\n",
    "# ======================================================\n",
    "print(\"\\n--- 2. STACKED LSTM (Robust Loss) ---\", flush=True)\n",
    "\n",
    "model_lstm = Sequential()\n",
    "\n",
    "# Strat 1: Return Sequences=True \n",
    "model_lstm.add(LSTM(64, return_sequences=True, input_shape=(WINDOW_SIZE, n_features)))\n",
    "model_lstm.add(Dropout(0.3)) # Cerinta: Dropout 0.2-0.4\n",
    "\n",
    "# Strat 2: Stacked\n",
    "model_lstm.add(LSTM(32, return_sequences=False))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "\n",
    "model_lstm.add(Dense(16, activation='relu'))\n",
    "model_lstm.add(Dense(1)) # Output final\n",
    "\n",
    "# Cerinta: Loss = Huber \n",
    "model_lstm.compile(optimizer='adam', loss=Huber(delta=1.0))\n",
    "\n",
    "# Antrenare\n",
    "start = time.time()\n",
    "print(\"   -> Antrenare LSTM...\", flush=True)\n",
    "history_lstm = model_lstm.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
    "timpi['LSTM'] = time.time() - start\n",
    "\n",
    "# Predictie\n",
    "pred_scaled = model_lstm.predict(X_test, verbose=0)\n",
    "rezultate['LSTM'] = scaler.inverse_transform(pred_scaled).flatten()\n",
    "print(f\"Gata. Timp: {timpi['LSTM']:.1f}s\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# MODEL 3: GRU (Cerinta: Comparatie cu LSTM)\n",
    "# ======================================================\n",
    "print(\"\\n--- 3. GRU ---\", flush=True)\n",
    "\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(64, return_sequences=True, input_shape=(WINDOW_SIZE, n_features)))\n",
    "model_gru.add(Dropout(0.3))\n",
    "model_gru.add(GRU(32, return_sequences=False))\n",
    "model_gru.add(Dense(1))\n",
    "\n",
    "# Folosim tot Huber \n",
    "model_gru.compile(optimizer='adam', loss=Huber(delta=1.0))\n",
    "\n",
    "# Antrenare\n",
    "start = time.time()\n",
    "print(\"   -> Antrenare GRU...\", flush=True)\n",
    "model_gru.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
    "timpi['GRU'] = time.time() - start\n",
    "\n",
    "# Predictie\n",
    "pred_scaled = model_gru.predict(X_test, verbose=0)\n",
    "rezultate['GRU'] = scaler.inverse_transform(pred_scaled).flatten()\n",
    "print(f\"Gata. Timp: {timpi['GRU']:.1f}s\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# MODEL 4: SIMPLE RNN (Cerinta: Gradient Clipping, LR mic)\n",
    "# ======================================================\n",
    "print(\"\\n--- 4. SIMPLE RNN (Vanilla - Tuned) ---\", flush=True)\n",
    "\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(32, input_shape=(WINDOW_SIZE, n_features), activation='tanh'))\n",
    "model_rnn.add(Dropout(0.2))\n",
    "model_rnn.add(Dense(1))\n",
    "\n",
    "# Cerinta: Gradient Clipping & Learning Rate mic\n",
    "# clipvalue=1.0 \n",
    "opt = Adam(learning_rate=0.0001, clipvalue=1.0)\n",
    "\n",
    "model_rnn.compile(optimizer=opt, loss='mse') \n",
    "\n",
    "# Antrenare\n",
    "start = time.time()\n",
    "print(\"   -> Antrenare RNN...\", flush=True)\n",
    "model_rnn.fit(X_train, y_train, epochs=5, batch_size=128, verbose=1)\n",
    "timpi['RNN'] = time.time() - start\n",
    "\n",
    "# Predictie\n",
    "pred_scaled = model_rnn.predict(X_test, verbose=0)\n",
    "rezultate['RNN'] = scaler.inverse_transform(pred_scaled).flatten()\n",
    "print(f\"Gata. Timp: {timpi['RNN']:.1f}s\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# MODEL 5: DeepAR (Probabilistic cu Laplace Loss)\n",
    "# ======================================================\n",
    "\n",
    "# 1. Definim functia de Loss (Laplace Negative Log Likelihood)\n",
    "def laplace_nll(y_true, y_pred):\n",
    "    # Modelul scoate 2 valori: Mu (Prezicerea) si Sigma (Incertitudinea)\n",
    "    mu = y_pred[:, 0]\n",
    "    sigma_raw = y_pred[:, 1]\n",
    "\n",
    "    # Sigma trebuie sa fie pozitiv, folosim softplus\n",
    "    sigma = tf.nn.softplus(sigma_raw) + 1e-6\n",
    "\n",
    "    # Formula matematica pentru Laplace: ln(2*sigma) + |y - mu| / sigma\n",
    "    nll = tf.math.log(2.0 * sigma) + tf.abs(y_true - mu) / sigma\n",
    "    return tf.reduce_mean(nll)\n",
    "\n",
    "# 2. Construim Modelul\n",
    "n_features = X_train.shape[2] \n",
    "\n",
    "model_deepar = Sequential()\n",
    "model_deepar.add(LSTM(64, return_sequences=True, input_shape=(WINDOW_SIZE, n_features)))\n",
    "model_deepar.add(Dropout(0.3))\n",
    "model_deepar.add(LSTM(32, return_sequences=False))\n",
    "model_deepar.add(Dropout(0.3))\n",
    "model_deepar.add(Dense(16, activation=\"relu\"))\n",
    "\n",
    "# Stratul final are 2 neuroni: unul pentru valoare (Mu), unul pentru variatie (Sigma)\n",
    "model_deepar.add(Dense(2))\n",
    "\n",
    "# Compilam cu functia noastra custom\n",
    "model_deepar.compile(optimizer='adam', loss=laplace_nll)\n",
    "\n",
    "# --- START TIMER ---\n",
    "print(\"   -> Antrenare DeepAR ...\", flush=True)\n",
    "start_time = time.time()\n",
    "\n",
    "# Antrenam\n",
    "model_deepar.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
    "end_time = time.time()\n",
    "# --- STOP TIMER ---\n",
    "\n",
    "timpi['DeepAR'] = end_time - start_time\n",
    "\n",
    "# Predictie\n",
    "print(\"   -> Predictie DeepAR...\", flush=True)\n",
    "# Modelul returneaza o matrice cu 2 coloane: [Mu, Sigma]\n",
    "pred_params = model_deepar.predict(X_test, verbose=0)\n",
    "\n",
    "# Noi luam doar prima coloana (Mu) ca fiind predictia propriu-zisa\n",
    "mu_pred_scaled = pred_params[:, 0]\n",
    "\n",
    "# O transformam inapoi in Watti\n",
    "pred_deepar = scaler.inverse_transform(mu_pred_scaled.reshape(-1, 1)).flatten()\n",
    "rezultate['DeepAR'] = pred_deepar\n",
    "\n",
    "print(f\"Gata. Timp antrenare: {timpi['DeepAR']:.1f} s.\")\n",
    "\n",
    "# ======================================================\n",
    "# MODEL 6: XGBoost & LightGBM (Feature Engineering)\n",
    "# ======================================================\n",
    "print(\"\\n--- 6. XGBoost & LightGBM (Machine Learning Clasic) ---\", flush=True)\n",
    "\n",
    "# 1. Pregatire date TABELARE\n",
    "df_ml = df_1min.copy()\n",
    "target_col = 'Aggregate'\n",
    "\n",
    "print(\"   -> Generare LAG-uri si Rolling Stats...\", flush=True)\n",
    "lags = [1, 5, 15, 60]\n",
    "for lag in lags:\n",
    "    df_ml[f'lag_{lag}'] = df_ml[target_col].shift(lag)\n",
    "\n",
    "window_size = 60\n",
    "df_ml['rolling_mean'] = df_ml[target_col].shift(1).rolling(window=window_size).mean()\n",
    "df_ml['rolling_std'] = df_ml[target_col].shift(1).rolling(window=window_size).std()\n",
    "df_ml.dropna(inplace=True)\n",
    "\n",
    "features = [col for col in df_ml.columns if 'lag_' in col or 'rolling_' in col or col in ['Cluster', 'Hour_Sin', 'Hour_Cos', 'IsWeekend']]\n",
    "\n",
    "X = df_ml[features].values\n",
    "y = df_ml[target_col].values\n",
    "\n",
    "# Split Train/Test (Respectand axa timpului)\n",
    "test_len = len(test_data)\n",
    "train_len = len(y) - test_len\n",
    "X_train_ml = X[:train_len]\n",
    "y_train_ml = y[:train_len]\n",
    "X_test_ml = X[train_len:]\n",
    "y_test_ml = y[train_len:]\n",
    "\n",
    "# --- XGBOOST ---\n",
    "print(\"\\n   -> Antrenare XGBoost...\", flush=True)\n",
    "start = time.time()\n",
    "model_xgb = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.05, max_depth=6, early_stopping_rounds=50, n_jobs=-1, random_state=42)\n",
    "model_xgb.fit(X_train_ml, y_train_ml, eval_set=[(X_test_ml, y_test_ml)], verbose=0)\n",
    "timp_xgb = time.time() - start\n",
    "\n",
    "pred_xgb = model_xgb.predict(X_test_ml)\n",
    "rezultate['XGBoost'] = pred_xgb\n",
    "timpi['XGBoost'] = timp_xgb\n",
    "\n",
    "# Calcul metrici XGBoost\n",
    "mae_xgb = mean_absolute_error(y_test_ml, pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_test_ml, pred_xgb)\n",
    "print(f\"XGBoost GATA ({timp_xgb:.1f}s) | MAE: {mae_xgb:.2f} W | MSE: {mse_xgb:.2f}\")\n",
    "\n",
    "# --- LIGHTGBM ---\n",
    "print(\"\\n   -> Antrenare LightGBM...\", flush=True)\n",
    "start = time.time()\n",
    "model_lgb = lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=31, n_jobs=-1, random_state=42, verbosity=-1)\n",
    "model_lgb.fit(X_train_ml, y_train_ml, eval_set=[(X_test_ml, y_test_ml)], eval_metric='mae', callbacks=[early_stopping(50), log_evaluation(0)])\n",
    "timp_lgb = time.time() - start\n",
    "\n",
    "pred_lgb = model_lgb.predict(X_test_ml)\n",
    "rezultate['LightGBM'] = pred_lgb\n",
    "timpi['LightGBM'] = timp_lgb\n",
    "\n",
    "# Calcul metrici LightGBM\n",
    "mae_lgb = mean_absolute_error(y_test_ml, pred_lgb)\n",
    "mse_lgb = mean_squared_error(y_test_ml, pred_lgb)\n",
    "print(f\"LightGBM GATA ({timp_lgb:.1f}s) | MAE: {mae_lgb:.2f} W | MSE: {mse_lgb:.2f}\")\n",
    "\n",
    "# ======================================================\n",
    "# SALVARE REZULTATE FINALE\n",
    "# ======================================================\n",
    "print(\"\\nSalvare pachet rezultate...\", flush=True)\n",
    "results_package = {\n",
    "    'rezultate_finale': rezultate,\n",
    "    'test_data_index': test_data.index,\n",
    "    'test_data_values': test_data['Aggregate'].values,\n",
    "    'timpi_antrenare': timpi,\n",
    "    'models_config': \"LSTM, Prophet, RNN, GRU, DeepAR, XGBoost, LightGBM\"\n",
    "}\n",
    "\n",
    "with open('model_results_final.pkl', 'wb') as f:\n",
    "    pickle.dump(results_package, f)\n",
    "\n",
    "print(\"TOTUL GATA! Rezultatele sunt in 'model_results_final.pkl. Poti rula 03_Analysis_Comparison.ipynb'\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnp_proiect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
